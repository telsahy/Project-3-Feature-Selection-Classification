{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import linear_model\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, SelectFromModel, f_regression\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and sampling the UCI data / basic EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIRST BATCH OF 2200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_pickle('../project_3/data/first_batch_X.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_pickle('../project_3/data/first_batch_labels.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SECOND BATCH OF 2200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = pd.read_pickle('../project_3/data/second_batch_X.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_2 = pd.read_pickle('../project_3/data/second_batch_labels.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THIRD BATCH OF 2200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3 = pd.read_pickle('../project_3/data/third_batch_X.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_3 = pd.read_pickle('../project_3/data/third_batch_labels.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMBINED DF OF 6800\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.read_pickle('../project_3/data/combined_df.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_000</th>\n",
       "      <th>feat_001</th>\n",
       "      <th>feat_002</th>\n",
       "      <th>feat_003</th>\n",
       "      <th>feat_004</th>\n",
       "      <th>feat_005</th>\n",
       "      <th>feat_006</th>\n",
       "      <th>feat_007</th>\n",
       "      <th>feat_008</th>\n",
       "      <th>feat_009</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_991</th>\n",
       "      <th>feat_992</th>\n",
       "      <th>feat_993</th>\n",
       "      <th>feat_994</th>\n",
       "      <th>feat_995</th>\n",
       "      <th>feat_996</th>\n",
       "      <th>feat_997</th>\n",
       "      <th>feat_998</th>\n",
       "      <th>feat_999</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>142191</th>\n",
       "      <td>-1.816446</td>\n",
       "      <td>-1.847394</td>\n",
       "      <td>-1.191931</td>\n",
       "      <td>0.891921</td>\n",
       "      <td>1.415293</td>\n",
       "      <td>0.431434</td>\n",
       "      <td>-0.140561</td>\n",
       "      <td>-0.119854</td>\n",
       "      <td>-1.235821</td>\n",
       "      <td>0.184390</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.776034</td>\n",
       "      <td>-0.610054</td>\n",
       "      <td>-0.044104</td>\n",
       "      <td>-0.054478</td>\n",
       "      <td>0.013141</td>\n",
       "      <td>-1.021682</td>\n",
       "      <td>0.085568</td>\n",
       "      <td>-0.213766</td>\n",
       "      <td>0.645228</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48223</th>\n",
       "      <td>0.605582</td>\n",
       "      <td>0.167287</td>\n",
       "      <td>1.509067</td>\n",
       "      <td>1.360146</td>\n",
       "      <td>1.661901</td>\n",
       "      <td>-0.581456</td>\n",
       "      <td>1.201053</td>\n",
       "      <td>0.375212</td>\n",
       "      <td>0.406078</td>\n",
       "      <td>1.325680</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.914473</td>\n",
       "      <td>-1.137351</td>\n",
       "      <td>0.843114</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>-0.013670</td>\n",
       "      <td>-0.157394</td>\n",
       "      <td>2.714091</td>\n",
       "      <td>0.879038</td>\n",
       "      <td>0.686568</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70337</th>\n",
       "      <td>2.193615</td>\n",
       "      <td>1.643293</td>\n",
       "      <td>-2.295479</td>\n",
       "      <td>-0.857736</td>\n",
       "      <td>-1.245261</td>\n",
       "      <td>-2.313969</td>\n",
       "      <td>-0.898803</td>\n",
       "      <td>0.517397</td>\n",
       "      <td>2.550697</td>\n",
       "      <td>0.334339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.628565</td>\n",
       "      <td>-1.487226</td>\n",
       "      <td>1.321013</td>\n",
       "      <td>-0.649784</td>\n",
       "      <td>-0.239126</td>\n",
       "      <td>-0.304112</td>\n",
       "      <td>0.290231</td>\n",
       "      <td>0.241242</td>\n",
       "      <td>0.571850</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66716</th>\n",
       "      <td>-0.138581</td>\n",
       "      <td>0.755474</td>\n",
       "      <td>-1.584437</td>\n",
       "      <td>0.646003</td>\n",
       "      <td>-1.441471</td>\n",
       "      <td>-0.487692</td>\n",
       "      <td>-0.036810</td>\n",
       "      <td>-1.375200</td>\n",
       "      <td>-2.258015</td>\n",
       "      <td>-1.522614</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.267789</td>\n",
       "      <td>1.013711</td>\n",
       "      <td>0.135463</td>\n",
       "      <td>-0.041005</td>\n",
       "      <td>0.636782</td>\n",
       "      <td>-0.905709</td>\n",
       "      <td>-1.824922</td>\n",
       "      <td>0.680373</td>\n",
       "      <td>0.930079</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55328</th>\n",
       "      <td>-0.350630</td>\n",
       "      <td>-0.510021</td>\n",
       "      <td>0.287249</td>\n",
       "      <td>0.694756</td>\n",
       "      <td>-0.132855</td>\n",
       "      <td>-1.371036</td>\n",
       "      <td>1.114947</td>\n",
       "      <td>0.478114</td>\n",
       "      <td>-2.097613</td>\n",
       "      <td>-0.692584</td>\n",
       "      <td>...</td>\n",
       "      <td>1.267077</td>\n",
       "      <td>0.232152</td>\n",
       "      <td>-1.107313</td>\n",
       "      <td>0.054655</td>\n",
       "      <td>-1.040566</td>\n",
       "      <td>-0.048720</td>\n",
       "      <td>0.386732</td>\n",
       "      <td>-0.585070</td>\n",
       "      <td>0.555567</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        feat_000  feat_001  feat_002  feat_003  feat_004  feat_005  feat_006  \\\n",
       "_id                                                                            \n",
       "142191 -1.816446 -1.847394 -1.191931  0.891921  1.415293  0.431434 -0.140561   \n",
       "48223   0.605582  0.167287  1.509067  1.360146  1.661901 -0.581456  1.201053   \n",
       "70337   2.193615  1.643293 -2.295479 -0.857736 -1.245261 -2.313969 -0.898803   \n",
       "66716  -0.138581  0.755474 -1.584437  0.646003 -1.441471 -0.487692 -0.036810   \n",
       "55328  -0.350630 -0.510021  0.287249  0.694756 -0.132855 -1.371036  1.114947   \n",
       "\n",
       "        feat_007  feat_008  feat_009   ...    feat_991  feat_992  feat_993  \\\n",
       "_id                                    ...                                   \n",
       "142191 -0.119854 -1.235821  0.184390   ...   -0.776034 -0.610054 -0.044104   \n",
       "48223   0.375212  0.406078  1.325680   ...   -0.914473 -1.137351  0.843114   \n",
       "70337   0.517397  2.550697  0.334339   ...    0.628565 -1.487226  1.321013   \n",
       "66716  -1.375200 -2.258015 -1.522614   ...   -1.267789  1.013711  0.135463   \n",
       "55328   0.478114 -2.097613 -0.692584   ...    1.267077  0.232152 -1.107313   \n",
       "\n",
       "        feat_994  feat_995  feat_996  feat_997  feat_998  feat_999  target  \n",
       "_id                                                                         \n",
       "142191 -0.054478  0.013141 -1.021682  0.085568 -0.213766  0.645228       0  \n",
       "48223   0.000906 -0.013670 -0.157394  2.714091  0.879038  0.686568       1  \n",
       "70337  -0.649784 -0.239126 -0.304112  0.290231  0.241242  0.571850       1  \n",
       "66716  -0.041005  0.636782 -0.905709 -1.824922  0.680373  0.930079       1  \n",
       "55328   0.054655 -1.040566 -0.048720  0.386732 -0.585070  0.555567       1  \n",
       "\n",
       "[5 rows x 1001 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_y = combined_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_X = combined_df.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_id\n",
       "142191    0\n",
       "48223     1\n",
       "70337     1\n",
       "66716     1\n",
       "55328     1\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_000</th>\n",
       "      <th>feat_001</th>\n",
       "      <th>feat_002</th>\n",
       "      <th>feat_003</th>\n",
       "      <th>feat_004</th>\n",
       "      <th>feat_005</th>\n",
       "      <th>feat_006</th>\n",
       "      <th>feat_007</th>\n",
       "      <th>feat_008</th>\n",
       "      <th>feat_009</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_990</th>\n",
       "      <th>feat_991</th>\n",
       "      <th>feat_992</th>\n",
       "      <th>feat_993</th>\n",
       "      <th>feat_994</th>\n",
       "      <th>feat_995</th>\n",
       "      <th>feat_996</th>\n",
       "      <th>feat_997</th>\n",
       "      <th>feat_998</th>\n",
       "      <th>feat_999</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>142191</th>\n",
       "      <td>-1.816446</td>\n",
       "      <td>-1.847394</td>\n",
       "      <td>-1.191931</td>\n",
       "      <td>0.891921</td>\n",
       "      <td>1.415293</td>\n",
       "      <td>0.431434</td>\n",
       "      <td>-0.140561</td>\n",
       "      <td>-0.119854</td>\n",
       "      <td>-1.235821</td>\n",
       "      <td>0.184390</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.288667</td>\n",
       "      <td>-0.776034</td>\n",
       "      <td>-0.610054</td>\n",
       "      <td>-0.044104</td>\n",
       "      <td>-0.054478</td>\n",
       "      <td>0.013141</td>\n",
       "      <td>-1.021682</td>\n",
       "      <td>0.085568</td>\n",
       "      <td>-0.213766</td>\n",
       "      <td>0.645228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48223</th>\n",
       "      <td>0.605582</td>\n",
       "      <td>0.167287</td>\n",
       "      <td>1.509067</td>\n",
       "      <td>1.360146</td>\n",
       "      <td>1.661901</td>\n",
       "      <td>-0.581456</td>\n",
       "      <td>1.201053</td>\n",
       "      <td>0.375212</td>\n",
       "      <td>0.406078</td>\n",
       "      <td>1.325680</td>\n",
       "      <td>...</td>\n",
       "      <td>1.523963</td>\n",
       "      <td>-0.914473</td>\n",
       "      <td>-1.137351</td>\n",
       "      <td>0.843114</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>-0.013670</td>\n",
       "      <td>-0.157394</td>\n",
       "      <td>2.714091</td>\n",
       "      <td>0.879038</td>\n",
       "      <td>0.686568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70337</th>\n",
       "      <td>2.193615</td>\n",
       "      <td>1.643293</td>\n",
       "      <td>-2.295479</td>\n",
       "      <td>-0.857736</td>\n",
       "      <td>-1.245261</td>\n",
       "      <td>-2.313969</td>\n",
       "      <td>-0.898803</td>\n",
       "      <td>0.517397</td>\n",
       "      <td>2.550697</td>\n",
       "      <td>0.334339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.899386</td>\n",
       "      <td>0.628565</td>\n",
       "      <td>-1.487226</td>\n",
       "      <td>1.321013</td>\n",
       "      <td>-0.649784</td>\n",
       "      <td>-0.239126</td>\n",
       "      <td>-0.304112</td>\n",
       "      <td>0.290231</td>\n",
       "      <td>0.241242</td>\n",
       "      <td>0.571850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66716</th>\n",
       "      <td>-0.138581</td>\n",
       "      <td>0.755474</td>\n",
       "      <td>-1.584437</td>\n",
       "      <td>0.646003</td>\n",
       "      <td>-1.441471</td>\n",
       "      <td>-0.487692</td>\n",
       "      <td>-0.036810</td>\n",
       "      <td>-1.375200</td>\n",
       "      <td>-2.258015</td>\n",
       "      <td>-1.522614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.663738</td>\n",
       "      <td>-1.267789</td>\n",
       "      <td>1.013711</td>\n",
       "      <td>0.135463</td>\n",
       "      <td>-0.041005</td>\n",
       "      <td>0.636782</td>\n",
       "      <td>-0.905709</td>\n",
       "      <td>-1.824922</td>\n",
       "      <td>0.680373</td>\n",
       "      <td>0.930079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55328</th>\n",
       "      <td>-0.350630</td>\n",
       "      <td>-0.510021</td>\n",
       "      <td>0.287249</td>\n",
       "      <td>0.694756</td>\n",
       "      <td>-0.132855</td>\n",
       "      <td>-1.371036</td>\n",
       "      <td>1.114947</td>\n",
       "      <td>0.478114</td>\n",
       "      <td>-2.097613</td>\n",
       "      <td>-0.692584</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.201236</td>\n",
       "      <td>1.267077</td>\n",
       "      <td>0.232152</td>\n",
       "      <td>-1.107313</td>\n",
       "      <td>0.054655</td>\n",
       "      <td>-1.040566</td>\n",
       "      <td>-0.048720</td>\n",
       "      <td>0.386732</td>\n",
       "      <td>-0.585070</td>\n",
       "      <td>0.555567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        feat_000  feat_001  feat_002  feat_003  feat_004  feat_005  feat_006  \\\n",
       "_id                                                                            \n",
       "142191 -1.816446 -1.847394 -1.191931  0.891921  1.415293  0.431434 -0.140561   \n",
       "48223   0.605582  0.167287  1.509067  1.360146  1.661901 -0.581456  1.201053   \n",
       "70337   2.193615  1.643293 -2.295479 -0.857736 -1.245261 -2.313969 -0.898803   \n",
       "66716  -0.138581  0.755474 -1.584437  0.646003 -1.441471 -0.487692 -0.036810   \n",
       "55328  -0.350630 -0.510021  0.287249  0.694756 -0.132855 -1.371036  1.114947   \n",
       "\n",
       "        feat_007  feat_008  feat_009    ...     feat_990  feat_991  feat_992  \\\n",
       "_id                                     ...                                    \n",
       "142191 -0.119854 -1.235821  0.184390    ...    -0.288667 -0.776034 -0.610054   \n",
       "48223   0.375212  0.406078  1.325680    ...     1.523963 -0.914473 -1.137351   \n",
       "70337   0.517397  2.550697  0.334339    ...     0.899386  0.628565 -1.487226   \n",
       "66716  -1.375200 -2.258015 -1.522614    ...     0.663738 -1.267789  1.013711   \n",
       "55328   0.478114 -2.097613 -0.692584    ...    -0.201236  1.267077  0.232152   \n",
       "\n",
       "        feat_993  feat_994  feat_995  feat_996  feat_997  feat_998  feat_999  \n",
       "_id                                                                           \n",
       "142191 -0.044104 -0.054478  0.013141 -1.021682  0.085568 -0.213766  0.645228  \n",
       "48223   0.843114  0.000906 -0.013670 -0.157394  2.714091  0.879038  0.686568  \n",
       "70337   1.321013 -0.649784 -0.239126 -0.304112  0.290231  0.241242  0.571850  \n",
       "66716   0.135463 -0.041005  0.636782 -0.905709 -1.824922  0.680373  0.930079  \n",
       "55328  -1.107313  0.054655 -1.040566 -0.048720  0.386732 -0.585070  0.555567  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = combined_X.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = list(corr_df[corr_df[corr_df.abs() >.5].count() > 1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feat_257',\n",
       " 'feat_269',\n",
       " 'feat_308',\n",
       " 'feat_315',\n",
       " 'feat_336',\n",
       " 'feat_341',\n",
       " 'feat_395',\n",
       " 'feat_504',\n",
       " 'feat_526',\n",
       " 'feat_639',\n",
       " 'feat_681',\n",
       " 'feat_701',\n",
       " 'feat_724',\n",
       " 'feat_736',\n",
       " 'feat_769',\n",
       " 'feat_808',\n",
       " 'feat_829',\n",
       " 'feat_867',\n",
       " 'feat_920',\n",
       " 'feat_956']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating DataFrame with 20 important/redundant features and eliminating noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_feat_df = combined_df[corrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6600, 20)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_feat_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA To Determine 5 Informative Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=20, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=20)\n",
    "pca.fit(imp_feat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.36168406e-01,   4.22326175e-02,  -8.13568324e-03,\n",
       "         -8.44270504e-02,   3.58661481e-01,   4.44137067e-01,\n",
       "          2.30454469e-01,   2.42374830e-01,  -2.18642824e-01,\n",
       "          3.50142920e-01,  -4.18510255e-02,   1.64833290e-01,\n",
       "         -1.60901514e-01,   1.69021940e-01,  -1.94539969e-01,\n",
       "         -6.89489982e-02,   3.32091975e-01,  -1.92567644e-01,\n",
       "         -6.67946651e-02,   2.94138044e-01],\n",
       "       [  2.01915455e-01,  -4.75648456e-01,  -1.68891496e-02,\n",
       "         -3.24293329e-01,   6.77613052e-02,  -2.35427791e-01,\n",
       "         -2.40252017e-01,   3.57588549e-03,  -3.33346180e-02,\n",
       "          1.62645428e-01,  -1.17990562e-01,   4.06575918e-01,\n",
       "          3.74531525e-01,  -1.35605307e-01,   1.47696612e-01,\n",
       "         -8.81478865e-02,  -2.28514439e-02,  -2.03331862e-01,\n",
       "          2.05148228e-01,   1.75488793e-01],\n",
       "       [ -2.23312266e-01,  -2.36702863e-01,   3.13580292e-01,\n",
       "         -5.96609459e-02,  -3.23283993e-01,  -1.64679663e-02,\n",
       "          1.01441181e-01,   3.59399358e-01,  -2.57379178e-01,\n",
       "          7.10599906e-02,  -1.75681857e-01,   2.05903644e-01,\n",
       "         -3.55586042e-01,  -2.63271137e-01,   1.91725227e-02,\n",
       "          4.05539260e-01,  -1.26880781e-01,   1.39292840e-01,\n",
       "         -7.69539548e-02,   3.75430741e-02],\n",
       "       [  2.35280755e-01,   5.56918764e-03,   1.33135711e-01,\n",
       "          3.21180367e-02,  -1.11271382e-01,   5.29326859e-03,\n",
       "         -2.76706811e-01,   2.34182485e-01,   2.04950567e-01,\n",
       "          9.00744881e-02,  -1.40312375e-01,  -2.75772458e-01,\n",
       "          1.48184663e-01,  -1.89174431e-01,   2.85926490e-01,\n",
       "         -1.90843662e-02,   5.03113252e-01,   2.40206151e-01,\n",
       "         -4.18179749e-01,   1.03061133e-01],\n",
       "       [  1.32322913e-01,   1.66430833e-01,   5.03152883e-01,\n",
       "         -2.23466656e-01,  -6.41716713e-02,   1.21114494e-01,\n",
       "         -2.08457097e-01,  -3.15099825e-01,  -1.60820439e-01,\n",
       "         -1.67103761e-06,   5.05703570e-01,   3.62152285e-02,\n",
       "          5.06742815e-02,  -2.89542864e-01,  -3.05599842e-01,\n",
       "         -4.61504673e-02,  -9.44770650e-03,   5.65235036e-02,\n",
       "         -7.83244085e-02,   1.26128711e-01],\n",
       "       [  5.98749688e-02,  -4.69765779e-02,  -6.96593431e-02,\n",
       "          9.57072233e-02,   8.55009184e-02,  -3.91641808e-01,\n",
       "         -1.96383963e-01,  -2.80742011e-01,   5.89194663e-02,\n",
       "         -2.56313040e-03,   1.33979073e-01,   2.86724444e-01,\n",
       "         -6.69601351e-01,   8.04672086e-02,   1.07088281e-01,\n",
       "         -5.37252075e-02,   3.59017459e-01,  -9.28353465e-03,\n",
       "         -1.04020052e-02,   1.40324428e-02],\n",
       "       [ -4.59380400e-03,  -6.54076392e-01,  -3.23129251e-02,\n",
       "         -3.18594497e-02,  -1.65389110e-01,   4.29811819e-01,\n",
       "         -1.48959112e-01,  -2.46876348e-01,   2.80246745e-02,\n",
       "          2.57003818e-02,   7.40882518e-02,  -4.09440063e-01,\n",
       "         -2.40244215e-01,   1.54357574e-01,   5.36660342e-02,\n",
       "         -7.95058948e-02,  -6.63395037e-02,  -5.97880450e-02,\n",
       "          2.82463177e-02,   2.79467383e-02],\n",
       "       [ -1.04482693e-01,   1.93576086e-01,  -6.25687154e-02,\n",
       "         -1.71240737e-02,  -5.79645755e-01,  -1.89916026e-01,\n",
       "          1.98832872e-02,  -1.24411083e-02,  -1.68262234e-01,\n",
       "          5.32637320e-01,   1.72974168e-01,  -9.67123443e-02,\n",
       "          7.84067708e-02,   2.45749545e-01,   1.11021589e-01,\n",
       "         -8.82672402e-02,   4.58732570e-02,  -3.59538837e-01,\n",
       "         -6.90696435e-02,  -2.66011560e-02],\n",
       "       [ -1.95618701e-02,   1.70629226e-01,  -1.52678579e-01,\n",
       "          2.07771505e-01,  -2.58065533e-01,   5.27685976e-01,\n",
       "         -2.88702603e-01,  -5.99896257e-02,   8.03293742e-02,\n",
       "         -2.10019330e-01,  -1.13974396e-02,   5.41901823e-01,\n",
       "          3.32558611e-02,  -1.36941050e-02,   2.32822799e-01,\n",
       "         -8.79541709e-03,  -8.43198924e-02,  -1.61058711e-01,\n",
       "         -1.93848922e-01,  -3.83683453e-02],\n",
       "       [  1.78430827e-01,   2.58400285e-01,  -2.13072288e-02,\n",
       "          6.47405499e-03,   2.39577730e-01,  -5.82292259e-02,\n",
       "         -5.47597973e-01,   1.95740616e-01,  -6.68519892e-02,\n",
       "          1.45135215e-01,  -1.06978207e-01,  -2.37672608e-01,\n",
       "         -2.38979948e-01,   5.89107855e-02,   7.72162582e-02,\n",
       "          1.20253453e-01,  -5.03751759e-01,  -1.42271540e-01,\n",
       "          1.30992131e-03,   2.31192246e-01],\n",
       "       [ -8.76776343e-02,  -1.48527908e-01,   6.01948493e-02,\n",
       "         -2.70649850e-02,  -6.24018324e-02,  -1.62905286e-01,\n",
       "         -1.94118564e-01,   4.71531631e-01,  -7.78323529e-02,\n",
       "         -5.31788379e-01,   2.16458048e-01,  -5.23711446e-02,\n",
       "          3.96784243e-02,   2.58867665e-01,  -2.82301046e-01,\n",
       "         -7.78574840e-02,   1.59155734e-01,  -3.72662303e-01,\n",
       "         -1.35434321e-01,  -9.67761837e-03],\n",
       "       [ -8.82518206e-02,   6.57097166e-02,   1.04037844e-01,\n",
       "          1.05651076e-02,   2.45851263e-01,   9.86475893e-02,\n",
       "         -1.30802167e-01,  -7.20685679e-02,  -4.19106517e-01,\n",
       "         -3.18035810e-02,  -1.01066786e-01,  -1.74845592e-01,\n",
       "          1.04608759e-02,  -2.85798137e-01,   2.64351568e-01,\n",
       "          8.30052412e-02,   2.41750780e-01,  -3.56078790e-01,\n",
       "          1.66430482e-01,  -5.43633687e-01],\n",
       "       [  5.75524381e-03,   1.58617464e-01,  -2.45046679e-01,\n",
       "         -2.30424400e-01,  -1.43529892e-01,   3.88336250e-03,\n",
       "          2.88095664e-01,  -4.15575502e-02,   1.92201743e-02,\n",
       "         -3.16800039e-01,   4.62652877e-02,  -1.98546920e-01,\n",
       "         -1.45320332e-01,  -4.16030733e-01,   2.64949269e-01,\n",
       "         -2.46706680e-02,   4.89605224e-02,  -2.99630095e-01,\n",
       "          1.17829942e-01,   4.92913239e-01],\n",
       "       [ -1.27369853e-01,  -1.01624399e-01,   1.56276160e-01,\n",
       "          4.02048085e-01,   1.20412650e-01,  -1.57632864e-01,\n",
       "          6.91676582e-02,  -3.67286937e-01,  -4.28520654e-01,\n",
       "         -1.43310356e-01,  -1.92936648e-01,  -2.95018693e-02,\n",
       "          2.22068492e-01,   1.67426904e-01,   9.93388202e-02,\n",
       "          1.05447782e-01,  -1.77069171e-02,  -5.68685778e-02,\n",
       "         -3.24159562e-01,   3.98910999e-01],\n",
       "       [ -2.78709185e-02,   1.89749731e-01,   2.14064745e-02,\n",
       "         -4.16626499e-02,  -2.91056088e-01,   8.40333392e-02,\n",
       "         -2.80973362e-01,  -1.47249517e-01,  -6.09765370e-02,\n",
       "         -1.10664739e-01,  -4.35690595e-01,  -5.29753471e-02,\n",
       "          4.19219999e-02,   1.56743791e-01,  -3.15815857e-01,\n",
       "          1.64309848e-01,   3.23322148e-01,   1.00595355e-01,\n",
       "          5.10787088e-01,   1.77199030e-01],\n",
       "       [ -1.04378255e-01,   1.36216958e-01,   2.24762324e-02,\n",
       "         -7.16713999e-01,   6.92971107e-02,   3.57649947e-02,\n",
       "          1.91323232e-02,  -1.45825640e-01,  -8.82747704e-02,\n",
       "         -1.65167852e-01,  -6.72384128e-02,   2.46791090e-02,\n",
       "         -7.88192582e-03,   4.35574404e-01,   2.79501564e-01,\n",
       "          1.83421130e-01,   3.76867868e-04,   1.55828866e-01,\n",
       "         -2.36764045e-01,  -8.09880649e-02],\n",
       "       [  2.52147312e-01,  -1.52291907e-03,   9.81577661e-02,\n",
       "         -1.24468522e-01,  -6.94071569e-02,  -6.75278178e-02,\n",
       "          1.35466602e-01,  -2.44998372e-01,   2.90875839e-01,\n",
       "          4.11878276e-03,  -4.51669825e-01,  -1.46306988e-02,\n",
       "         -1.02411797e-01,  -1.16728162e-01,  -3.68567013e-01,\n",
       "          8.00680231e-02,  -8.96171066e-02,  -4.25324222e-01,\n",
       "         -3.78944982e-01,  -1.89199614e-01],\n",
       "       [  5.43565977e-01,  -3.27536699e-02,  -4.49408745e-01,\n",
       "         -3.37873473e-02,  -1.98973950e-01,  -4.26210355e-02,\n",
       "          3.33607239e-02,   1.87958256e-02,  -5.38071673e-01,\n",
       "         -1.19483418e-01,  -1.03572912e-02,  -5.21554068e-03,\n",
       "         -4.16114188e-02,  -6.79931583e-02,  -1.60354570e-01,\n",
       "         -7.82640223e-02,  -6.09592357e-02,   2.63421006e-01,\n",
       "         -1.32723164e-01,  -1.56947789e-01],\n",
       "       [  5.88482521e-01,   3.36152965e-02,   4.63766346e-01,\n",
       "          1.59181983e-01,  -1.14428003e-01,   2.00671937e-02,\n",
       "          2.70374994e-01,   7.00397725e-02,   5.73610000e-02,\n",
       "         -1.57512327e-01,   3.39016913e-02,   2.38058868e-02,\n",
       "         -4.30272690e-02,   2.94959204e-01,   3.23441361e-01,\n",
       "          6.16282046e-02,  -6.25281143e-02,  -8.71718285e-02,\n",
       "          2.82987863e-01,  -4.43128219e-02],\n",
       "       [  1.49843606e-01,  -7.87816400e-02,  -2.65120108e-01,\n",
       "          8.08002993e-02,   6.82323280e-02,   7.91741531e-03,\n",
       "         -6.43928319e-03,  -6.09853482e-02,   1.37269137e-01,\n",
       "          7.00040151e-02,   3.42143306e-01,  -2.42511966e-02,\n",
       "          1.56249014e-01,   2.01854603e-02,  -6.56680110e-02,\n",
       "          8.29052543e-01,   1.30108675e-01,  -1.05799604e-01,\n",
       "          1.88402600e-03,   7.96535516e-03]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f305597e400>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABI0AAAFzCAYAAACzaPn6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJEkNJo0kSZIkSZLU8L8ngINsOSppPgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f305da63da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,6))\n",
    "\n",
    "X = np.arange(1,21)\n",
    "cumulative_explained_variance_uci = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "plt.plot(X, cumulative_explained_variance_uci, '-o')\n",
    "plt.bar(X, pca.explained_variance_ratio_, align='center', alpha=0.5)\n",
    "\n",
    "for i, j in zip(X, np.cumsum(pca.explained_variance_ratio_)):\n",
    "    plt.annotate(str(j.round(4)), xy=(i+.2,j-.02))\n",
    "    \n",
    "plt.xlabel('PCA components')\n",
    "plt.ylabel('Explained variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = pca.transform(imp_feat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6600, 20), (6600,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca.shape, combined_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_pca,\n",
    "                                                    combined_y,\n",
    "                                                    test_size = .3,\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Final Model with KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pipe = Pipeline([\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_params = {\n",
    "    'knn__n_neighbors': range(1,10,2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_gs = GridSearchCV(knn_pipe, param_grid=knn_params, cv=5, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('knn', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'knn__n_neighbors': range(1, 10, 2)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>0.00489831</td>\n",
       "      <td>0.00480027</td>\n",
       "      <td>0.00486102</td>\n",
       "      <td>0.00481205</td>\n",
       "      <td>0.00613556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.0274444</td>\n",
       "      <td>0.0302214</td>\n",
       "      <td>0.0211982</td>\n",
       "      <td>0.025016</td>\n",
       "      <td>0.0159978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>0.784416</td>\n",
       "      <td>0.782251</td>\n",
       "      <td>0.778139</td>\n",
       "      <td>0.777489</td>\n",
       "      <td>0.774892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>0.842587</td>\n",
       "      <td>0.834037</td>\n",
       "      <td>0.891775</td>\n",
       "      <td>0.857413</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_knn__n_neighbors</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'knn__n_neighbors': 7}</td>\n",
       "      <td>{'knn__n_neighbors': 9}</td>\n",
       "      <td>{'knn__n_neighbors': 3}</td>\n",
       "      <td>{'knn__n_neighbors': 5}</td>\n",
       "      <td>{'knn__n_neighbors': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>0.788961</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.781385</td>\n",
       "      <td>0.780303</td>\n",
       "      <td>0.766234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>0.84145</td>\n",
       "      <td>0.833063</td>\n",
       "      <td>0.883387</td>\n",
       "      <td>0.854978</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>0.808442</td>\n",
       "      <td>0.799784</td>\n",
       "      <td>0.778139</td>\n",
       "      <td>0.788961</td>\n",
       "      <td>0.784632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>0.83631</td>\n",
       "      <td>0.826028</td>\n",
       "      <td>0.888258</td>\n",
       "      <td>0.854978</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>0.780303</td>\n",
       "      <td>0.778139</td>\n",
       "      <td>0.786797</td>\n",
       "      <td>0.778139</td>\n",
       "      <td>0.784632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>0.847673</td>\n",
       "      <td>0.84145</td>\n",
       "      <td>0.893128</td>\n",
       "      <td>0.857684</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>0.777056</td>\n",
       "      <td>0.786797</td>\n",
       "      <td>0.771645</td>\n",
       "      <td>0.775974</td>\n",
       "      <td>0.774892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_score</th>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.83631</td>\n",
       "      <td>0.898268</td>\n",
       "      <td>0.863366</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>0.767316</td>\n",
       "      <td>0.767316</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.764069</td>\n",
       "      <td>0.764069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_score</th>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.856061</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.000218233</td>\n",
       "      <td>5.79304e-05</td>\n",
       "      <td>7.22946e-05</td>\n",
       "      <td>5.59752e-05</td>\n",
       "      <td>0.00127285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.000347188</td>\n",
       "      <td>0.000996333</td>\n",
       "      <td>0.000133256</td>\n",
       "      <td>0.000440011</td>\n",
       "      <td>0.000308852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.0138663</td>\n",
       "      <td>0.0107443</td>\n",
       "      <td>0.00560267</td>\n",
       "      <td>0.00802911</td>\n",
       "      <td>0.0087388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0.00413315</td>\n",
       "      <td>0.00501411</td>\n",
       "      <td>0.0053514</td>\n",
       "      <td>0.00313666</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              3                        4  \\\n",
       "mean_fit_time                        0.00489831               0.00480027   \n",
       "mean_score_time                       0.0274444                0.0302214   \n",
       "mean_test_score                        0.784416                 0.782251   \n",
       "mean_train_score                       0.842587                 0.834037   \n",
       "param_knn__n_neighbors                        7                        9   \n",
       "params                  {'knn__n_neighbors': 7}  {'knn__n_neighbors': 9}   \n",
       "rank_test_score                               1                        2   \n",
       "split0_test_score                      0.788961                 0.779221   \n",
       "split0_train_score                      0.84145                 0.833063   \n",
       "split1_test_score                      0.808442                 0.799784   \n",
       "split1_train_score                      0.83631                 0.826028   \n",
       "split2_test_score                      0.780303                 0.778139   \n",
       "split2_train_score                     0.847673                  0.84145   \n",
       "split3_test_score                      0.777056                 0.786797   \n",
       "split3_train_score                     0.846591                  0.83631   \n",
       "split4_test_score                      0.767316                 0.767316   \n",
       "split4_train_score                     0.840909                 0.833333   \n",
       "std_fit_time                        0.000218233              5.79304e-05   \n",
       "std_score_time                      0.000347188              0.000996333   \n",
       "std_test_score                        0.0138663                0.0107443   \n",
       "std_train_score                      0.00413315               0.00501411   \n",
       "\n",
       "                                              1                        2  \\\n",
       "mean_fit_time                        0.00486102               0.00481205   \n",
       "mean_score_time                       0.0211982                 0.025016   \n",
       "mean_test_score                        0.778139                 0.777489   \n",
       "mean_train_score                       0.891775                 0.857413   \n",
       "param_knn__n_neighbors                        3                        5   \n",
       "params                  {'knn__n_neighbors': 3}  {'knn__n_neighbors': 5}   \n",
       "rank_test_score                               3                        4   \n",
       "split0_test_score                      0.781385                 0.780303   \n",
       "split0_train_score                     0.883387                 0.854978   \n",
       "split1_test_score                      0.778139                 0.788961   \n",
       "split1_train_score                     0.888258                 0.854978   \n",
       "split2_test_score                      0.786797                 0.778139   \n",
       "split2_train_score                     0.893128                 0.857684   \n",
       "split3_test_score                      0.771645                 0.775974   \n",
       "split3_train_score                     0.898268                 0.863366   \n",
       "split4_test_score                      0.772727                 0.764069   \n",
       "split4_train_score                     0.895833                 0.856061   \n",
       "std_fit_time                        7.22946e-05              5.59752e-05   \n",
       "std_score_time                      0.000133256              0.000440011   \n",
       "std_test_score                       0.00560267               0.00802911   \n",
       "std_train_score                       0.0053514               0.00313666   \n",
       "\n",
       "                                              0  \n",
       "mean_fit_time                        0.00613556  \n",
       "mean_score_time                       0.0159978  \n",
       "mean_test_score                        0.774892  \n",
       "mean_train_score                              1  \n",
       "param_knn__n_neighbors                        1  \n",
       "params                  {'knn__n_neighbors': 1}  \n",
       "rank_test_score                               5  \n",
       "split0_test_score                      0.766234  \n",
       "split0_train_score                            1  \n",
       "split1_test_score                      0.784632  \n",
       "split1_train_score                            1  \n",
       "split2_test_score                      0.784632  \n",
       "split2_train_score                            1  \n",
       "split3_test_score                      0.774892  \n",
       "split3_train_score                            1  \n",
       "split4_test_score                      0.764069  \n",
       "split4_train_score                            1  \n",
       "std_fit_time                         0.00127285  \n",
       "std_score_time                      0.000308852  \n",
       "std_test_score                        0.0087388  \n",
       "std_train_score                               0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(knn_gs.cv_results_).sort_values(by='rank_test_score').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=7, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79292929292929293"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.77      0.79       996\n",
      "          1       0.78      0.81      0.80       984\n",
      "\n",
      "avg / total       0.79      0.79      0.79      1980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Final Model with DECISION TREE CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_pipe =  Pipeline([\n",
    "    ('dtc', DecisionTreeClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_parms = {\n",
    "    'dtc__max_depth': [3,7,11,None],\n",
    "    'dtc__max_features': [3,5,7,None]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_gs = GridSearchCV(dtc_pipe, dtc_parms, cv = 5, verbose = 1, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('dtc', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'dtc__max_depth': [3, 7, 11, None], 'dtc__max_features': [3, 5, 7, None]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>15</th>\n",
       "      <th>11</th>\n",
       "      <th>10</th>\n",
       "      <th>9</th>\n",
       "      <th>13</th>\n",
       "      <th>7</th>\n",
       "      <th>14</th>\n",
       "      <th>12</th>\n",
       "      <th>8</th>\n",
       "      <th>6</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>3</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>0.0300978</td>\n",
       "      <td>0.0265832</td>\n",
       "      <td>0.0144415</td>\n",
       "      <td>0.0126462</td>\n",
       "      <td>0.0144762</td>\n",
       "      <td>0.0210452</td>\n",
       "      <td>0.0159763</td>\n",
       "      <td>0.0125329</td>\n",
       "      <td>0.0109379</td>\n",
       "      <td>0.0121181</td>\n",
       "      <td>0.0102671</td>\n",
       "      <td>0.0101666</td>\n",
       "      <td>0.0135105</td>\n",
       "      <td>0.00726032</td>\n",
       "      <td>0.0082449</td>\n",
       "      <td>0.011558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.000613832</td>\n",
       "      <td>0.000655222</td>\n",
       "      <td>0.00059824</td>\n",
       "      <td>0.000579834</td>\n",
       "      <td>0.000660086</td>\n",
       "      <td>0.000540543</td>\n",
       "      <td>0.000581026</td>\n",
       "      <td>0.000627708</td>\n",
       "      <td>0.000539064</td>\n",
       "      <td>0.000496292</td>\n",
       "      <td>0.000501442</td>\n",
       "      <td>0.000488615</td>\n",
       "      <td>0.000470591</td>\n",
       "      <td>0.000457287</td>\n",
       "      <td>0.000465012</td>\n",
       "      <td>0.00065403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>0.716234</td>\n",
       "      <td>0.709091</td>\n",
       "      <td>0.703463</td>\n",
       "      <td>0.700433</td>\n",
       "      <td>0.697835</td>\n",
       "      <td>0.694589</td>\n",
       "      <td>0.693506</td>\n",
       "      <td>0.689177</td>\n",
       "      <td>0.688745</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.668615</td>\n",
       "      <td>0.662771</td>\n",
       "      <td>0.640693</td>\n",
       "      <td>0.638745</td>\n",
       "      <td>0.624892</td>\n",
       "      <td>0.617532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>1</td>\n",
       "      <td>0.874134</td>\n",
       "      <td>0.833874</td>\n",
       "      <td>0.818723</td>\n",
       "      <td>1</td>\n",
       "      <td>0.762284</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.819859</td>\n",
       "      <td>0.736959</td>\n",
       "      <td>0.705303</td>\n",
       "      <td>0.719697</td>\n",
       "      <td>0.65119</td>\n",
       "      <td>0.651732</td>\n",
       "      <td>0.639015</td>\n",
       "      <td>0.633658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_dtc__max_depth</th>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_dtc__max_features</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'dtc__max_depth': None, 'dtc__max_features': ...</td>\n",
       "      <td>{'dtc__max_depth': 11, 'dtc__max_features': None}</td>\n",
       "      <td>{'dtc__max_depth': 11, 'dtc__max_features': 7}</td>\n",
       "      <td>{'dtc__max_depth': 11, 'dtc__max_features': 5}</td>\n",
       "      <td>{'dtc__max_depth': None, 'dtc__max_features': 5}</td>\n",
       "      <td>{'dtc__max_depth': 7, 'dtc__max_features': None}</td>\n",
       "      <td>{'dtc__max_depth': None, 'dtc__max_features': 7}</td>\n",
       "      <td>{'dtc__max_depth': None, 'dtc__max_features': 3}</td>\n",
       "      <td>{'dtc__max_depth': 11, 'dtc__max_features': 3}</td>\n",
       "      <td>{'dtc__max_depth': 7, 'dtc__max_features': 7}</td>\n",
       "      <td>{'dtc__max_depth': 7, 'dtc__max_features': 3}</td>\n",
       "      <td>{'dtc__max_depth': 7, 'dtc__max_features': 5}</td>\n",
       "      <td>{'dtc__max_depth': 3, 'dtc__max_features': None}</td>\n",
       "      <td>{'dtc__max_depth': 3, 'dtc__max_features': 5}</td>\n",
       "      <td>{'dtc__max_depth': 3, 'dtc__max_features': 7}</td>\n",
       "      <td>{'dtc__max_depth': 3, 'dtc__max_features': 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>0.725108</td>\n",
       "      <td>0.717532</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.71645</td>\n",
       "      <td>0.694805</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.668831</td>\n",
       "      <td>0.686147</td>\n",
       "      <td>0.685065</td>\n",
       "      <td>0.694805</td>\n",
       "      <td>0.675325</td>\n",
       "      <td>0.655844</td>\n",
       "      <td>0.647186</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.649351</td>\n",
       "      <td>0.647186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>1</td>\n",
       "      <td>0.881223</td>\n",
       "      <td>0.825216</td>\n",
       "      <td>0.796266</td>\n",
       "      <td>1</td>\n",
       "      <td>0.758929</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.806548</td>\n",
       "      <td>0.737554</td>\n",
       "      <td>0.703463</td>\n",
       "      <td>0.716991</td>\n",
       "      <td>0.648268</td>\n",
       "      <td>0.672078</td>\n",
       "      <td>0.647186</td>\n",
       "      <td>0.665855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>0.728355</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.687229</td>\n",
       "      <td>0.683983</td>\n",
       "      <td>0.717532</td>\n",
       "      <td>0.677489</td>\n",
       "      <td>0.692641</td>\n",
       "      <td>0.687229</td>\n",
       "      <td>0.67316</td>\n",
       "      <td>0.667749</td>\n",
       "      <td>0.669913</td>\n",
       "      <td>0.662338</td>\n",
       "      <td>0.633117</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.654762</td>\n",
       "      <td>0.643939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>1</td>\n",
       "      <td>0.869589</td>\n",
       "      <td>0.820346</td>\n",
       "      <td>0.834957</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76434</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.819535</td>\n",
       "      <td>0.744048</td>\n",
       "      <td>0.715639</td>\n",
       "      <td>0.714015</td>\n",
       "      <td>0.655032</td>\n",
       "      <td>0.642316</td>\n",
       "      <td>0.670184</td>\n",
       "      <td>0.666126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>0.717532</td>\n",
       "      <td>0.707792</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.711039</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.709957</td>\n",
       "      <td>0.694805</td>\n",
       "      <td>0.709957</td>\n",
       "      <td>0.712121</td>\n",
       "      <td>0.702381</td>\n",
       "      <td>0.664502</td>\n",
       "      <td>0.675325</td>\n",
       "      <td>0.640693</td>\n",
       "      <td>0.63961</td>\n",
       "      <td>0.623377</td>\n",
       "      <td>0.608225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>1</td>\n",
       "      <td>0.85119</td>\n",
       "      <td>0.833874</td>\n",
       "      <td>0.828193</td>\n",
       "      <td>1</td>\n",
       "      <td>0.751353</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.804654</td>\n",
       "      <td>0.724838</td>\n",
       "      <td>0.688312</td>\n",
       "      <td>0.723485</td>\n",
       "      <td>0.640422</td>\n",
       "      <td>0.647998</td>\n",
       "      <td>0.646374</td>\n",
       "      <td>0.622294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>0.705628</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.722944</td>\n",
       "      <td>0.711039</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.705628</td>\n",
       "      <td>0.717532</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.693723</td>\n",
       "      <td>0.679654</td>\n",
       "      <td>0.665584</td>\n",
       "      <td>0.66342</td>\n",
       "      <td>0.633117</td>\n",
       "      <td>0.617965</td>\n",
       "      <td>0.601732</td>\n",
       "      <td>0.617965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_score</th>\n",
       "      <td>1</td>\n",
       "      <td>0.884199</td>\n",
       "      <td>0.843344</td>\n",
       "      <td>0.813312</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76921</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.838203</td>\n",
       "      <td>0.734848</td>\n",
       "      <td>0.704004</td>\n",
       "      <td>0.718074</td>\n",
       "      <td>0.655032</td>\n",
       "      <td>0.63447</td>\n",
       "      <td>0.621483</td>\n",
       "      <td>0.63447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.702381</td>\n",
       "      <td>0.688312</td>\n",
       "      <td>0.679654</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.701299</td>\n",
       "      <td>0.693723</td>\n",
       "      <td>0.680736</td>\n",
       "      <td>0.679654</td>\n",
       "      <td>0.664502</td>\n",
       "      <td>0.667749</td>\n",
       "      <td>0.656926</td>\n",
       "      <td>0.649351</td>\n",
       "      <td>0.650433</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.570346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_score</th>\n",
       "      <td>1</td>\n",
       "      <td>0.88447</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.820887</td>\n",
       "      <td>1</td>\n",
       "      <td>0.767587</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.830357</td>\n",
       "      <td>0.743506</td>\n",
       "      <td>0.715097</td>\n",
       "      <td>0.72592</td>\n",
       "      <td>0.657197</td>\n",
       "      <td>0.661797</td>\n",
       "      <td>0.609848</td>\n",
       "      <td>0.579545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.000638148</td>\n",
       "      <td>0.000257238</td>\n",
       "      <td>0.000356479</td>\n",
       "      <td>0.00042508</td>\n",
       "      <td>0.000307785</td>\n",
       "      <td>7.6952e-05</td>\n",
       "      <td>0.000584283</td>\n",
       "      <td>0.000611171</td>\n",
       "      <td>0.000335236</td>\n",
       "      <td>0.000759832</td>\n",
       "      <td>0.00279112</td>\n",
       "      <td>0.000177664</td>\n",
       "      <td>4.49154e-05</td>\n",
       "      <td>0.000356427</td>\n",
       "      <td>0.000365418</td>\n",
       "      <td>0.00256946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>2.91388e-05</td>\n",
       "      <td>1.76671e-05</td>\n",
       "      <td>5.46145e-05</td>\n",
       "      <td>4.16377e-05</td>\n",
       "      <td>4.32601e-05</td>\n",
       "      <td>3.30154e-05</td>\n",
       "      <td>2.33041e-05</td>\n",
       "      <td>5.36096e-05</td>\n",
       "      <td>1.78804e-05</td>\n",
       "      <td>1.82521e-05</td>\n",
       "      <td>2.14589e-05</td>\n",
       "      <td>1.62108e-05</td>\n",
       "      <td>2.20227e-05</td>\n",
       "      <td>7.33307e-06</td>\n",
       "      <td>4.41068e-06</td>\n",
       "      <td>0.000174741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.00976188</td>\n",
       "      <td>0.01261</td>\n",
       "      <td>0.0140776</td>\n",
       "      <td>0.0153878</td>\n",
       "      <td>0.012271</td>\n",
       "      <td>0.0137986</td>\n",
       "      <td>0.0154182</td>\n",
       "      <td>0.0106787</td>\n",
       "      <td>0.013493</td>\n",
       "      <td>0.0147916</td>\n",
       "      <td>0.00383551</td>\n",
       "      <td>0.00693317</td>\n",
       "      <td>0.00681045</td>\n",
       "      <td>0.0186374</td>\n",
       "      <td>0.0241184</td>\n",
       "      <td>0.0278927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0126921</td>\n",
       "      <td>0.0100931</td>\n",
       "      <td>0.0133528</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00649711</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0130785</td>\n",
       "      <td>0.00699791</td>\n",
       "      <td>0.00996523</td>\n",
       "      <td>0.00436605</td>\n",
       "      <td>0.00616598</td>\n",
       "      <td>0.013534</td>\n",
       "      <td>0.0212156</td>\n",
       "      <td>0.0320897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        15  \\\n",
       "mean_fit_time                                                    0.0300978   \n",
       "mean_score_time                                                0.000613832   \n",
       "mean_test_score                                                   0.716234   \n",
       "mean_train_score                                                         1   \n",
       "param_dtc__max_depth                                                  None   \n",
       "param_dtc__max_features                                               None   \n",
       "params                   {'dtc__max_depth': None, 'dtc__max_features': ...   \n",
       "rank_test_score                                                          1   \n",
       "split0_test_score                                                 0.725108   \n",
       "split0_train_score                                                       1   \n",
       "split1_test_score                                                 0.728355   \n",
       "split1_train_score                                                       1   \n",
       "split2_test_score                                                 0.717532   \n",
       "split2_train_score                                                       1   \n",
       "split3_test_score                                                 0.705628   \n",
       "split3_train_score                                                       1   \n",
       "split4_test_score                                                 0.704545   \n",
       "split4_train_score                                                       1   \n",
       "std_fit_time                                                   0.000638148   \n",
       "std_score_time                                                 2.91388e-05   \n",
       "std_test_score                                                  0.00976188   \n",
       "std_train_score                                                          0   \n",
       "\n",
       "                                                                        11  \\\n",
       "mean_fit_time                                                    0.0265832   \n",
       "mean_score_time                                                0.000655222   \n",
       "mean_test_score                                                   0.709091   \n",
       "mean_train_score                                                  0.874134   \n",
       "param_dtc__max_depth                                                    11   \n",
       "param_dtc__max_features                                               None   \n",
       "params                   {'dtc__max_depth': 11, 'dtc__max_features': None}   \n",
       "rank_test_score                                                          2   \n",
       "split0_test_score                                                 0.717532   \n",
       "split0_train_score                                                0.881223   \n",
       "split1_test_score                                                 0.690476   \n",
       "split1_train_score                                                0.869589   \n",
       "split2_test_score                                                 0.707792   \n",
       "split2_train_score                                                 0.85119   \n",
       "split3_test_score                                                 0.727273   \n",
       "split3_train_score                                                0.884199   \n",
       "split4_test_score                                                 0.702381   \n",
       "split4_train_score                                                 0.88447   \n",
       "std_fit_time                                                   0.000257238   \n",
       "std_score_time                                                 1.76671e-05   \n",
       "std_test_score                                                     0.01261   \n",
       "std_train_score                                                  0.0126921   \n",
       "\n",
       "                                                                     10  \\\n",
       "mean_fit_time                                                 0.0144415   \n",
       "mean_score_time                                              0.00059824   \n",
       "mean_test_score                                                0.703463   \n",
       "mean_train_score                                               0.833874   \n",
       "param_dtc__max_depth                                                 11   \n",
       "param_dtc__max_features                                               7   \n",
       "params                   {'dtc__max_depth': 11, 'dtc__max_features': 7}   \n",
       "rank_test_score                                                       3   \n",
       "split0_test_score                                              0.704545   \n",
       "split0_train_score                                             0.825216   \n",
       "split1_test_score                                              0.687229   \n",
       "split1_train_score                                             0.820346   \n",
       "split2_test_score                                              0.714286   \n",
       "split2_train_score                                             0.833874   \n",
       "split3_test_score                                              0.722944   \n",
       "split3_train_score                                             0.843344   \n",
       "split4_test_score                                              0.688312   \n",
       "split4_train_score                                             0.846591   \n",
       "std_fit_time                                                0.000356479   \n",
       "std_score_time                                              5.46145e-05   \n",
       "std_test_score                                                0.0140776   \n",
       "std_train_score                                               0.0100931   \n",
       "\n",
       "                                                                     9   \\\n",
       "mean_fit_time                                                 0.0126462   \n",
       "mean_score_time                                             0.000579834   \n",
       "mean_test_score                                                0.700433   \n",
       "mean_train_score                                               0.818723   \n",
       "param_dtc__max_depth                                                 11   \n",
       "param_dtc__max_features                                               5   \n",
       "params                   {'dtc__max_depth': 11, 'dtc__max_features': 5}   \n",
       "rank_test_score                                                       4   \n",
       "split0_test_score                                               0.71645   \n",
       "split0_train_score                                             0.796266   \n",
       "split1_test_score                                              0.683983   \n",
       "split1_train_score                                             0.834957   \n",
       "split2_test_score                                              0.711039   \n",
       "split2_train_score                                             0.828193   \n",
       "split3_test_score                                              0.711039   \n",
       "split3_train_score                                             0.813312   \n",
       "split4_test_score                                              0.679654   \n",
       "split4_train_score                                             0.820887   \n",
       "std_fit_time                                                 0.00042508   \n",
       "std_score_time                                              4.16377e-05   \n",
       "std_test_score                                                0.0153878   \n",
       "std_train_score                                               0.0133528   \n",
       "\n",
       "                                                                       13  \\\n",
       "mean_fit_time                                                   0.0144762   \n",
       "mean_score_time                                               0.000660086   \n",
       "mean_test_score                                                  0.697835   \n",
       "mean_train_score                                                        1   \n",
       "param_dtc__max_depth                                                 None   \n",
       "param_dtc__max_features                                                 5   \n",
       "params                   {'dtc__max_depth': None, 'dtc__max_features': 5}   \n",
       "rank_test_score                                                         5   \n",
       "split0_test_score                                                0.694805   \n",
       "split0_train_score                                                      1   \n",
       "split1_test_score                                                0.717532   \n",
       "split1_train_score                                                      1   \n",
       "split2_test_score                                                0.704545   \n",
       "split2_train_score                                                      1   \n",
       "split3_test_score                                                0.681818   \n",
       "split3_train_score                                                      1   \n",
       "split4_test_score                                                0.690476   \n",
       "split4_train_score                                                      1   \n",
       "std_fit_time                                                  0.000307785   \n",
       "std_score_time                                                4.32601e-05   \n",
       "std_test_score                                                   0.012271   \n",
       "std_train_score                                                         0   \n",
       "\n",
       "                                                                       7   \\\n",
       "mean_fit_time                                                   0.0210452   \n",
       "mean_score_time                                               0.000540543   \n",
       "mean_test_score                                                  0.694589   \n",
       "mean_train_score                                                 0.762284   \n",
       "param_dtc__max_depth                                                    7   \n",
       "param_dtc__max_features                                              None   \n",
       "params                   {'dtc__max_depth': 7, 'dtc__max_features': None}   \n",
       "rank_test_score                                                         6   \n",
       "split0_test_score                                                0.678571   \n",
       "split0_train_score                                               0.758929   \n",
       "split1_test_score                                                0.677489   \n",
       "split1_train_score                                                0.76434   \n",
       "split2_test_score                                                0.709957   \n",
       "split2_train_score                                               0.751353   \n",
       "split3_test_score                                                0.705628   \n",
       "split3_train_score                                                0.76921   \n",
       "split4_test_score                                                0.701299   \n",
       "split4_train_score                                               0.767587   \n",
       "std_fit_time                                                   7.6952e-05   \n",
       "std_score_time                                                3.30154e-05   \n",
       "std_test_score                                                  0.0137986   \n",
       "std_train_score                                                0.00649711   \n",
       "\n",
       "                                                                       14  \\\n",
       "mean_fit_time                                                   0.0159763   \n",
       "mean_score_time                                               0.000581026   \n",
       "mean_test_score                                                  0.693506   \n",
       "mean_train_score                                                        1   \n",
       "param_dtc__max_depth                                                 None   \n",
       "param_dtc__max_features                                                 7   \n",
       "params                   {'dtc__max_depth': None, 'dtc__max_features': 7}   \n",
       "rank_test_score                                                         7   \n",
       "split0_test_score                                                0.668831   \n",
       "split0_train_score                                                      1   \n",
       "split1_test_score                                                0.692641   \n",
       "split1_train_score                                                      1   \n",
       "split2_test_score                                                0.694805   \n",
       "split2_train_score                                                      1   \n",
       "split3_test_score                                                0.717532   \n",
       "split3_train_score                                                      1   \n",
       "split4_test_score                                                0.693723   \n",
       "split4_train_score                                                      1   \n",
       "std_fit_time                                                  0.000584283   \n",
       "std_score_time                                                2.33041e-05   \n",
       "std_test_score                                                  0.0154182   \n",
       "std_train_score                                                         0   \n",
       "\n",
       "                                                                       12  \\\n",
       "mean_fit_time                                                   0.0125329   \n",
       "mean_score_time                                               0.000627708   \n",
       "mean_test_score                                                  0.689177   \n",
       "mean_train_score                                                        1   \n",
       "param_dtc__max_depth                                                 None   \n",
       "param_dtc__max_features                                                 3   \n",
       "params                   {'dtc__max_depth': None, 'dtc__max_features': 3}   \n",
       "rank_test_score                                                         8   \n",
       "split0_test_score                                                0.686147   \n",
       "split0_train_score                                                      1   \n",
       "split1_test_score                                                0.687229   \n",
       "split1_train_score                                                      1   \n",
       "split2_test_score                                                0.709957   \n",
       "split2_train_score                                                      1   \n",
       "split3_test_score                                                0.681818   \n",
       "split3_train_score                                                      1   \n",
       "split4_test_score                                                0.680736   \n",
       "split4_train_score                                                      1   \n",
       "std_fit_time                                                  0.000611171   \n",
       "std_score_time                                                5.36096e-05   \n",
       "std_test_score                                                  0.0106787   \n",
       "std_train_score                                                         0   \n",
       "\n",
       "                                                                     8   \\\n",
       "mean_fit_time                                                 0.0109379   \n",
       "mean_score_time                                             0.000539064   \n",
       "mean_test_score                                                0.688745   \n",
       "mean_train_score                                               0.819859   \n",
       "param_dtc__max_depth                                                 11   \n",
       "param_dtc__max_features                                               3   \n",
       "params                   {'dtc__max_depth': 11, 'dtc__max_features': 3}   \n",
       "rank_test_score                                                       9   \n",
       "split0_test_score                                              0.685065   \n",
       "split0_train_score                                             0.806548   \n",
       "split1_test_score                                               0.67316   \n",
       "split1_train_score                                             0.819535   \n",
       "split2_test_score                                              0.712121   \n",
       "split2_train_score                                             0.804654   \n",
       "split3_test_score                                              0.693723   \n",
       "split3_train_score                                             0.838203   \n",
       "split4_test_score                                              0.679654   \n",
       "split4_train_score                                             0.830357   \n",
       "std_fit_time                                                0.000335236   \n",
       "std_score_time                                              1.78804e-05   \n",
       "std_test_score                                                 0.013493   \n",
       "std_train_score                                               0.0130785   \n",
       "\n",
       "                                                                    6   \\\n",
       "mean_fit_time                                                0.0121181   \n",
       "mean_score_time                                            0.000496292   \n",
       "mean_test_score                                               0.681818   \n",
       "mean_train_score                                              0.736959   \n",
       "param_dtc__max_depth                                                 7   \n",
       "param_dtc__max_features                                              7   \n",
       "params                   {'dtc__max_depth': 7, 'dtc__max_features': 7}   \n",
       "rank_test_score                                                     10   \n",
       "split0_test_score                                             0.694805   \n",
       "split0_train_score                                            0.737554   \n",
       "split1_test_score                                             0.667749   \n",
       "split1_train_score                                            0.744048   \n",
       "split2_test_score                                             0.702381   \n",
       "split2_train_score                                            0.724838   \n",
       "split3_test_score                                             0.679654   \n",
       "split3_train_score                                            0.734848   \n",
       "split4_test_score                                             0.664502   \n",
       "split4_train_score                                            0.743506   \n",
       "std_fit_time                                               0.000759832   \n",
       "std_score_time                                             1.82521e-05   \n",
       "std_test_score                                               0.0147916   \n",
       "std_train_score                                             0.00699791   \n",
       "\n",
       "                                                                    4   \\\n",
       "mean_fit_time                                                0.0102671   \n",
       "mean_score_time                                            0.000501442   \n",
       "mean_test_score                                               0.668615   \n",
       "mean_train_score                                              0.705303   \n",
       "param_dtc__max_depth                                                 7   \n",
       "param_dtc__max_features                                              3   \n",
       "params                   {'dtc__max_depth': 7, 'dtc__max_features': 3}   \n",
       "rank_test_score                                                     11   \n",
       "split0_test_score                                             0.675325   \n",
       "split0_train_score                                            0.703463   \n",
       "split1_test_score                                             0.669913   \n",
       "split1_train_score                                            0.715639   \n",
       "split2_test_score                                             0.664502   \n",
       "split2_train_score                                            0.688312   \n",
       "split3_test_score                                             0.665584   \n",
       "split3_train_score                                            0.704004   \n",
       "split4_test_score                                             0.667749   \n",
       "split4_train_score                                            0.715097   \n",
       "std_fit_time                                                0.00279112   \n",
       "std_score_time                                             2.14589e-05   \n",
       "std_test_score                                              0.00383551   \n",
       "std_train_score                                             0.00996523   \n",
       "\n",
       "                                                                    5   \\\n",
       "mean_fit_time                                                0.0101666   \n",
       "mean_score_time                                            0.000488615   \n",
       "mean_test_score                                               0.662771   \n",
       "mean_train_score                                              0.719697   \n",
       "param_dtc__max_depth                                                 7   \n",
       "param_dtc__max_features                                              5   \n",
       "params                   {'dtc__max_depth': 7, 'dtc__max_features': 5}   \n",
       "rank_test_score                                                     12   \n",
       "split0_test_score                                             0.655844   \n",
       "split0_train_score                                            0.716991   \n",
       "split1_test_score                                             0.662338   \n",
       "split1_train_score                                            0.714015   \n",
       "split2_test_score                                             0.675325   \n",
       "split2_train_score                                            0.723485   \n",
       "split3_test_score                                              0.66342   \n",
       "split3_train_score                                            0.718074   \n",
       "split4_test_score                                             0.656926   \n",
       "split4_train_score                                             0.72592   \n",
       "std_fit_time                                               0.000177664   \n",
       "std_score_time                                             1.62108e-05   \n",
       "std_test_score                                              0.00693317   \n",
       "std_train_score                                             0.00436605   \n",
       "\n",
       "                                                                       3   \\\n",
       "mean_fit_time                                                   0.0135105   \n",
       "mean_score_time                                               0.000470591   \n",
       "mean_test_score                                                  0.640693   \n",
       "mean_train_score                                                  0.65119   \n",
       "param_dtc__max_depth                                                    3   \n",
       "param_dtc__max_features                                              None   \n",
       "params                   {'dtc__max_depth': 3, 'dtc__max_features': None}   \n",
       "rank_test_score                                                        13   \n",
       "split0_test_score                                                0.647186   \n",
       "split0_train_score                                               0.648268   \n",
       "split1_test_score                                                0.633117   \n",
       "split1_train_score                                               0.655032   \n",
       "split2_test_score                                                0.640693   \n",
       "split2_train_score                                               0.640422   \n",
       "split3_test_score                                                0.633117   \n",
       "split3_train_score                                               0.655032   \n",
       "split4_test_score                                                0.649351   \n",
       "split4_train_score                                               0.657197   \n",
       "std_fit_time                                                  4.49154e-05   \n",
       "std_score_time                                                2.20227e-05   \n",
       "std_test_score                                                 0.00681045   \n",
       "std_train_score                                                0.00616598   \n",
       "\n",
       "                                                                    1   \\\n",
       "mean_fit_time                                               0.00726032   \n",
       "mean_score_time                                            0.000457287   \n",
       "mean_test_score                                               0.638745   \n",
       "mean_train_score                                              0.651732   \n",
       "param_dtc__max_depth                                                 3   \n",
       "param_dtc__max_features                                              5   \n",
       "params                   {'dtc__max_depth': 3, 'dtc__max_features': 5}   \n",
       "rank_test_score                                                     14   \n",
       "split0_test_score                                             0.666667   \n",
       "split0_train_score                                            0.672078   \n",
       "split1_test_score                                             0.619048   \n",
       "split1_train_score                                            0.642316   \n",
       "split2_test_score                                              0.63961   \n",
       "split2_train_score                                            0.647998   \n",
       "split3_test_score                                             0.617965   \n",
       "split3_train_score                                             0.63447   \n",
       "split4_test_score                                             0.650433   \n",
       "split4_train_score                                            0.661797   \n",
       "std_fit_time                                               0.000356427   \n",
       "std_score_time                                             7.33307e-06   \n",
       "std_test_score                                               0.0186374   \n",
       "std_train_score                                               0.013534   \n",
       "\n",
       "                                                                    2   \\\n",
       "mean_fit_time                                                0.0082449   \n",
       "mean_score_time                                            0.000465012   \n",
       "mean_test_score                                               0.624892   \n",
       "mean_train_score                                              0.639015   \n",
       "param_dtc__max_depth                                                 3   \n",
       "param_dtc__max_features                                              7   \n",
       "params                   {'dtc__max_depth': 3, 'dtc__max_features': 7}   \n",
       "rank_test_score                                                     15   \n",
       "split0_test_score                                             0.649351   \n",
       "split0_train_score                                            0.647186   \n",
       "split1_test_score                                             0.654762   \n",
       "split1_train_score                                            0.670184   \n",
       "split2_test_score                                             0.623377   \n",
       "split2_train_score                                            0.646374   \n",
       "split3_test_score                                             0.601732   \n",
       "split3_train_score                                            0.621483   \n",
       "split4_test_score                                             0.595238   \n",
       "split4_train_score                                            0.609848   \n",
       "std_fit_time                                               0.000365418   \n",
       "std_score_time                                             4.41068e-06   \n",
       "std_test_score                                               0.0241184   \n",
       "std_train_score                                              0.0212156   \n",
       "\n",
       "                                                                    0   \n",
       "mean_fit_time                                                 0.011558  \n",
       "mean_score_time                                             0.00065403  \n",
       "mean_test_score                                               0.617532  \n",
       "mean_train_score                                              0.633658  \n",
       "param_dtc__max_depth                                                 3  \n",
       "param_dtc__max_features                                              3  \n",
       "params                   {'dtc__max_depth': 3, 'dtc__max_features': 3}  \n",
       "rank_test_score                                                     16  \n",
       "split0_test_score                                             0.647186  \n",
       "split0_train_score                                            0.665855  \n",
       "split1_test_score                                             0.643939  \n",
       "split1_train_score                                            0.666126  \n",
       "split2_test_score                                             0.608225  \n",
       "split2_train_score                                            0.622294  \n",
       "split3_test_score                                             0.617965  \n",
       "split3_train_score                                             0.63447  \n",
       "split4_test_score                                             0.570346  \n",
       "split4_train_score                                            0.579545  \n",
       "std_fit_time                                                0.00256946  \n",
       "std_score_time                                             0.000174741  \n",
       "std_test_score                                               0.0278927  \n",
       "std_train_score                                              0.0320897  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dtc_gs.cv_results_).sort_values(by='rank_test_score').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_clf = DecisionTreeClassifier(max_depth=None, max_features=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71666666666666667"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dtc = dtc_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.72      0.72       996\n",
      "          1       0.72      0.71      0.71       984\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_dtc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Final Model with LOGISTIC REGRESSION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_pipe_1 = Pipeline([\n",
    "    ('lnr',  LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_param_1 = {\n",
    "    'lnr__C': [10,25,50,75,100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple2_gs = GridSearchCV(simple_pipe_1, param_grid=simple_param_1, cv=5, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('lnr', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'lnr__C': [10, 25, 50, 75, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple2_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>0.0200002</td>\n",
       "      <td>0.0175156</td>\n",
       "      <td>0.0123077</td>\n",
       "      <td>0.0126987</td>\n",
       "      <td>0.0190299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.00358047</td>\n",
       "      <td>0.00233026</td>\n",
       "      <td>0.00112486</td>\n",
       "      <td>0.00109167</td>\n",
       "      <td>0.00337472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>0.604113</td>\n",
       "      <td>0.604113</td>\n",
       "      <td>0.604113</td>\n",
       "      <td>0.604113</td>\n",
       "      <td>0.604113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>0.606872</td>\n",
       "      <td>0.606872</td>\n",
       "      <td>0.606872</td>\n",
       "      <td>0.606872</td>\n",
       "      <td>0.606872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_lnr__C</th>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>75</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'lnr__C': 10}</td>\n",
       "      <td>{'lnr__C': 25}</td>\n",
       "      <td>{'lnr__C': 50}</td>\n",
       "      <td>{'lnr__C': 75}</td>\n",
       "      <td>{'lnr__C': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>0.609307</td>\n",
       "      <td>0.609307</td>\n",
       "      <td>0.609307</td>\n",
       "      <td>0.609307</td>\n",
       "      <td>0.609307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>0.604437</td>\n",
       "      <td>0.604437</td>\n",
       "      <td>0.604437</td>\n",
       "      <td>0.604437</td>\n",
       "      <td>0.604437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>0.598485</td>\n",
       "      <td>0.598485</td>\n",
       "      <td>0.598485</td>\n",
       "      <td>0.598485</td>\n",
       "      <td>0.598485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>0.606872</td>\n",
       "      <td>0.606872</td>\n",
       "      <td>0.606872</td>\n",
       "      <td>0.606872</td>\n",
       "      <td>0.606872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>0.600649</td>\n",
       "      <td>0.600649</td>\n",
       "      <td>0.600649</td>\n",
       "      <td>0.600649</td>\n",
       "      <td>0.600649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>0.609037</td>\n",
       "      <td>0.609037</td>\n",
       "      <td>0.609037</td>\n",
       "      <td>0.609037</td>\n",
       "      <td>0.609037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.613636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_score</th>\n",
       "      <td>0.608766</td>\n",
       "      <td>0.608766</td>\n",
       "      <td>0.608766</td>\n",
       "      <td>0.608766</td>\n",
       "      <td>0.608766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>0.598485</td>\n",
       "      <td>0.598485</td>\n",
       "      <td>0.598485</td>\n",
       "      <td>0.598485</td>\n",
       "      <td>0.598485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_score</th>\n",
       "      <td>0.605249</td>\n",
       "      <td>0.605249</td>\n",
       "      <td>0.605249</td>\n",
       "      <td>0.605249</td>\n",
       "      <td>0.605249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.00625532</td>\n",
       "      <td>0.00245862</td>\n",
       "      <td>0.0026633</td>\n",
       "      <td>0.00235452</td>\n",
       "      <td>0.00171897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.00309398</td>\n",
       "      <td>0.00157272</td>\n",
       "      <td>0.000830867</td>\n",
       "      <td>0.000499195</td>\n",
       "      <td>0.00143713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.00621329</td>\n",
       "      <td>0.00621329</td>\n",
       "      <td>0.00621329</td>\n",
       "      <td>0.00621329</td>\n",
       "      <td>0.00621329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0.00183505</td>\n",
       "      <td>0.00183505</td>\n",
       "      <td>0.00183505</td>\n",
       "      <td>0.00183505</td>\n",
       "      <td>0.00183505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0               1               2  \\\n",
       "mean_fit_time            0.0200002       0.0175156       0.0123077   \n",
       "mean_score_time         0.00358047      0.00233026      0.00112486   \n",
       "mean_test_score           0.604113        0.604113        0.604113   \n",
       "mean_train_score          0.606872        0.606872        0.606872   \n",
       "param_lnr__C                    10              25              50   \n",
       "params              {'lnr__C': 10}  {'lnr__C': 25}  {'lnr__C': 50}   \n",
       "rank_test_score                  1               1               1   \n",
       "split0_test_score         0.609307        0.609307        0.609307   \n",
       "split0_train_score        0.604437        0.604437        0.604437   \n",
       "split1_test_score         0.598485        0.598485        0.598485   \n",
       "split1_train_score        0.606872        0.606872        0.606872   \n",
       "split2_test_score         0.600649        0.600649        0.600649   \n",
       "split2_train_score        0.609037        0.609037        0.609037   \n",
       "split3_test_score         0.613636        0.613636        0.613636   \n",
       "split3_train_score        0.608766        0.608766        0.608766   \n",
       "split4_test_score         0.598485        0.598485        0.598485   \n",
       "split4_train_score        0.605249        0.605249        0.605249   \n",
       "std_fit_time            0.00625532      0.00245862       0.0026633   \n",
       "std_score_time          0.00309398      0.00157272     0.000830867   \n",
       "std_test_score          0.00621329      0.00621329      0.00621329   \n",
       "std_train_score         0.00183505      0.00183505      0.00183505   \n",
       "\n",
       "                                 3                4  \n",
       "mean_fit_time            0.0126987        0.0190299  \n",
       "mean_score_time         0.00109167       0.00337472  \n",
       "mean_test_score           0.604113         0.604113  \n",
       "mean_train_score          0.606872         0.606872  \n",
       "param_lnr__C                    75              100  \n",
       "params              {'lnr__C': 75}  {'lnr__C': 100}  \n",
       "rank_test_score                  1                1  \n",
       "split0_test_score         0.609307         0.609307  \n",
       "split0_train_score        0.604437         0.604437  \n",
       "split1_test_score         0.598485         0.598485  \n",
       "split1_train_score        0.606872         0.606872  \n",
       "split2_test_score         0.600649         0.600649  \n",
       "split2_train_score        0.609037         0.609037  \n",
       "split3_test_score         0.613636         0.613636  \n",
       "split3_train_score        0.608766         0.608766  \n",
       "split4_test_score         0.598485         0.598485  \n",
       "split4_train_score        0.605249         0.605249  \n",
       "std_fit_time            0.00235452       0.00171897  \n",
       "std_score_time         0.000499195       0.00143713  \n",
       "std_test_score          0.00621329       0.00621329  \n",
       "std_train_score         0.00183505       0.00183505  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(simple2_gs.cv_results_).sort_values(by='rank_test_score').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6141414141414141"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple2_gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The highest average score of 0.79 was acheived using KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
